\chapter{Related Work}

\section{Related Work esciece15}

This question of identifying when a user is reacting to some other users' content can be considered a dual 
question to ``is the user going to react to this message'', a question often asked in studies around influence online. 
The usual approach to the latter question is to identify relevant message or network features in the set of (message, reaction), where the reactions are those tagged by the system (e.g., explicit retweets and/or replies in Twitter).  
Using these features, it is possible to build models that predict the likelihood of a reaction given a message.

Such studies often focus on computational models for predicting retweet behavior.  
For instance, Suh et al. \cite{Suh2010} apply Principal Component Analysis to decompose tweets into a space of characteristics, showing that URLs, hashtags, the number of followers and followees, and the age of the account are correlated with retweet behavior. 
Comarela et al. \cite{Comarela2012} also find that previous responses to the same tweeter, the tweeter's sending rate, and the age of a tweet influence retweeting, proposing two ranking methods for reordering tweets to increase retweeting.  
Petrovic et al. \cite{Petrovic2011} built a \textit{passive-aggressive} classifier for answering that took into consideration social characteristics of the tweets' author as well as tweets' textual features, finding that social features are more informative.  
Peng et al. \cite{Peng2011} used \textit{Conditional Random Fields} to model the probability of how a user retweets a message. 

Other studies look at variations of the problem.  
Artzi et al. \cite{Artzi2012} applied \textit{Multiple Additive Regression-Trees} and \textit{Maximum Entropy Classifiers} to predict both retweets and replies, while Hong et al. \cite{Hong2011} model both the binary question of whether a tweet would be retweeted and the eventual number of retweets a message might accrue.  
Luo et al. \cite{Luo2013} and Wang et al. \cite{Wang2012} approach a similar problem: given a user and their followers, who will retweet a message generated by the user?  Both created classifiers to predict the followers that would retweet a message.  
Liu et al. \cite{Liu2013} studied the social network of questions and answers in \textit{Sina Weibo} looking for characteristics that are associated with a higher number of answers.

These prior works identify a number of useful features that researchers often take into consideration when developing their models.  These include textual features of Tweets, user preferences or characteristics, and features of users' networks including pairwise relationships and graph structure.  Table \ref{tab:characteristics} presents a number of these features and the papers that have used them in response prediction.  This paper's focus on the prevalence of implicit responses complements these works by identifying tweets that, although not marked as a response, are in fact likely to be real responses.  Such tweets would appear as errors or noise to these models; methods for identifying them might improve both these models and our understanding of why these features matter. For instance, account age might turn out to predict retweet behavior mostly because more experienced users are simply more likely to press the retweet button than new users, rather than having a higher innate propensity to retweet.

When trying to identify non-explicit responses, having a model that explains which messages a user is most likely to be interested can be valuable; that is, the problem of understanding these (message, user) relationships is related to the problem of understanding the (message, reaction) relationships.  
The main stream of research related to modeling user interests in Twitter is the feed personalization problem, defined by Berkovsky et al. \cite{Berkovsky2015} as creating mechanisms that promote and optimize exhibition of interesting content (messages or people, for instance) according to each user's particular preferences and context.  
In their survey, they break approaches to feed personalization into three main groups: approaches that consider the pairwise relationship between author and consumer of content, approaches that take into consideration the graph structure of the social network, and approaches that deal with textual information from the users.

As with studies of retweet prediction, feed personalization approaches often use indicators of tie strength as proxies for potential interest.  
Schaal et al. \cite{Schaal2012} measure pairwise user similarity through tf vectors and topic similarity using LDA. 
Goyal et al. \cite{Goyal2010} estimate pairwise influence probability based on the user activity (action log).  There are a wide variety of such features; Gilbert and Karahalios \cite{Gilbert2009} estimate pairwise tie strength based on Facebook data based on over 70 features in categories including intensity, intimacy, duration, reciprocal services, structural, emotional support, and social distance.  

Network structure also plays an important role in feed personalization.  
Uysal et al. \cite{Uysal2011} developed a personalized tweet ranking method based on a retweet metric, useful in reordering feeds or distributing items to users more likely to retweet. 
Paek et al. \cite{Paek2010} asked Facebook users about the perceived importance of items in their timeline, developed classifiers to identify important messages and friends, and studied the predictive power of a number of features including likes, number of comments, presence of links and images, textual information, and shared background information. 
Both the tie strength and network structure approaches rely on explicit interaction as a tool for estimating tie strength; just as with retweet prediction, being able to identify non-explicit responses might improve these models.

Most related to this paper are text-focused approaches.  Text is commonly used in feed personalization, by comparing content similarity of Tweets or users to a user's previous activity.  
Hannon et al. \cite{Hannon2011} developed a system for follower recommendation on Twitter based on $tf\mhyphen idf$ similarity between the users' newsfeeds. 
Burgess et al. \cite{Burgess2013} propose a system to automatically select users when creating lists. The method adopts $tf\mhyphen idf$ to compare content users generated, among other measures and evaluates the performance comparing user-made lists with those generated by the system.  This work informs ours by providing evidence that $tf\mhyphen idf$-based methods are useful in understanding attention and interest.

%% DC 24: Would still like to see at least some meaningful sorting, even if there aren't subheaders.  Right now it's just a big unordered list, which is not helpful.
\begin{table}[htbp]
	\centering
	\caption{Some characteristics from online social networks that are commonly used to model users' behavior.} 
	\tabcolsep=0.11cm
	\singlespacing
	\fontsize{7pt}{8pt}\selectfont
	\begin{tabular}{|>{\raggedright\centering\arraybackslash}m{1.5cm}|m{6.8cm}|}
		\hline
		\textbf{Characteristic} & \centering\arraybackslash \textbf{Description} \\ \hline
		URL 																								& Presence of a link in a tweet. \cite{Artzi2012,Comarela2012,Peng2011,Petrovic2011,Suh2010} \\ \hline
		Number of hashtags 																	& Number of hashtags in a tweet. \cite{Artzi2012,Comarela2012,Peng2011,Petrovic2011} \\ \hline
		Number of mentions 																	& Number of mentions in a tweet. \cite{Artzi2012,Comarela2012,Liu2013,Peng2011,Petrovic2011,Suh2010} \\ \hline
		Number of followers 																& Number of followers of the author. \cite{Artzi2012,Hong2011,Liu2013,Luo2013,Petrovic2011,Suh2010,Wang2012} \\ \hline
		Number of followees 																& Number of followees of the author. \cite{Artzi2012,Hong2011,Luo2013,Petrovic2011,Suh2010,Wang2012} \\ \hline
		Presence in lists 																	& Number of times that an author has been added to lists. \cite{Luo2013,Petrovic2011} \\ \hline
		Verified 																						& If the author has a verified account. \cite{Luo2013,Petrovic2011} \\ \hline
		Ratio of followers over followees												& Ratio $followers/followees$ or its inverse. \cite{Artzi2012,Peng2011} \\ \hline
		N-grams 																						& Presence of possible n-grams in the text. Usually used together with dimensionality reduction methods. \cite{Artzi2012,Petrovic2011} \\ \hline
		Number of Stop Words 																& Number of stop words in the tweet. \cite{Artzi2012} \\ \hline
		Time 																								& Time when the user received the tweet. \cite{Artzi2012,Liu2013} \\ \hline
		Day of week 																				& Day of the week when the user received the tweet. \cite{Artzi2012} \\ \hline
		Time zone 																					& If the author and the receiver of a tweet are in the same time zone. \cite{Luo2013} \\ \hline
		Wait time 																					& Average time a user takes to reply or retweet a message. \cite{Comarela2012,Hong2011} \\ \hline
		Timeline position 													& How many messages on average a user receives between receiving and replying (or retweeting) a tweet. \cite{Comarela2012} \\ \hline
		Tweet age 																					& When the tweet being retweeted was originally created. \cite{Comarela2012,Hong2011} \\ \hline
		Previous interaction 																& If the user has already replied to or retweeted the author in the past. \cite{Comarela2012,Luo2013,Wang2012} \\ \hline
		Author's activity 																	& Absolute number, frequency, or distribution that represents how the author tweets. \cite{Comarela2012,Hong2011,Liu2013,Luo2013,Peng2011,Petrovic2011,Suh2010,Wang2012} \\ \hline
		Followees activity 																	& Absolute number, frequency, or distribution that represents how the followees of the user tweet. \cite{Peng2011} \\ \hline
		Tweet size 																					& Number of characters of the tweet. \cite{Comarela2012,Petrovic2011} \\ \hline
		Author's PageRank 																	& PageRank of the author. \cite{Hong2011,Wang2012} \\ \hline
		Reciprocal links 
																		& If the author and the user follow each other. \cite{Hong2011,Peng2011,Wang2012} \\ \hline
		Reciprocal followers 																& Number of followers that the author and the user share. \cite{Peng2011,Wang2012} \\ \hline
		Reciprocal followees 																& Number of followees that the author and the user share. \cite{Peng2011,Wang2012} \\ \hline
		Reciprocal mentions 																& Number of tweets where the author mentions the user or the user mentions the author. \cite{Peng2011} \\ \hline
		Reciprocal retweets 																& Number of retweets that the author and the user share. \cite{Peng2011} \\ \hline
		Clustering coefficients 															& Clustering coefficients of the network structure. \cite{Hong2011} \\ \hline
		Previously retweeted message 												& If and how many times a message has been retweeted by other users in the past. \cite{Hong2011,Suh2010} \\ \hline
		Author's retweet count 															& How many messages of the author have been previously retweeted. \cite{Hong2011,Peng2011} \\ \hline
		Emoticons					 												& If there is an emoticon in the tweet. \cite{Liu2013} \\ \hline
		Message topic 																			& Topic identification on the message text or topic similarity measures between the author's interests and the message topic. \cite{Liu2013,Luo2013,Peng2011,Wang2012} \\ \hline
		Language 																						& User's profile language. \cite{Petrovic2011,Wang2012} \\ \hline
		Favorite 																						& If the tweet has been marked as a favorite by the author. \cite{Petrovic2011,Suh2010} \\ \hline
		Response 																						& If the message received is an answer to a previous message. \cite{Petrovic2011} \\ \hline
		Account age 																				& Age of the tweet author's account. \cite{Suh2010,Wang2012} \\ \hline
		Trending topics words 															& If the tweet has \textit{trending topics}' terms. \cite{Petrovic2011} \\ \hline
		Reciprocal hashtags 																& Number of hashtags in common that the author and the user shared in the past. \cite{Wang2012} \\ \hline
		Reciprocal URLs																			& Number of URLs in common that the author and the user shared in the past. \cite{Wang2012} \\ \hline
		Number of lists																			& Number of lists that an author created. \cite{Wang2012} \\ \hline
	\end{tabular}
	\label{tab:characteristics}
\end{table}


\section{Time matters www16} 

\subsection{Why accounting for time is important}

Communities grow and, with time, die. For any community, its users play a role in its evolution, but they are also simultaneously affected by the evolution of the community. Untangling this interplay can help make sense of patterns of activity in a community.

One useful way to understand the evolution of a community and its users is through time, as it provides a linear account of the growth (or decay) of overall activity, types of content, and social norms and structure.  One aspect of time often considered is the tenure of a user in the community, as in studies around modeling users' preferences \cite{McAuley2013} or analyzing the evolution of their language \cite{Danescu-niculescu-mizil2013}.  These analyses uncover insights about the lifecycle of a user in a community: users' preferences and behavior change with their age in a community \cite{Panciera2010}, while their early experiences and activity shape future outcomes predictably \cite{Tan2015,Yang2009,Panciera2009, Miller2015}. 

However, much past work on online communities ignores the time at which a user joins the community and analyzes all users together.
This might be a mistake: communities may grow denser or sparser with time \cite{Leskovec2005}, develop new norms \cite{Kooti2010}, and enact policies and rules guiding people's behavior \cite{Butler2008}.
These changes mean that people experience different versions of a community at different times, which can, in turn, affect their observed behavior. This interaction with the state of a community can confound conclusions about people's behavior, because the differences one observes may simply due to changes in the community, rather than any significant change in the outcome variable of interest or the user population.  


\subsection{Cohorts are analytically useful}

A common method to control for such confounds is cohort analysis, widely used in fields such as sociology \cite{Mason2012,Glenn2005}, economics \cite{Attanasio1993,Beldona2005}, and medicine \cite{Howartz1996,Davis2010}. A cohort is defined as a group of people who share a common characteristic, generally with respect to time. For example, people born in the same year, or those who joined a school at the same time, or got exposed to an intervention at similar times can be considered as cohorts.  People in a cohort are assumed to be exposed to the same state of the world and thus are more comparable to each other than to people in other cohorts. 

For example, sociological studies often use students who join a school in the same year to understand the effect of interventions \cite{Goyette2008,Alexander2012}, and condition on the year in which people were born to understand people's  behavior, such as variations in financial decision-making \cite{Attanasio1993} or opinions on issues \cite{Firebaugh1988,Jennings1996}. Similarly, medical studies interpret effects of drugs using cohorts of people within the same age group or amount of exposure to correlated conditions \cite{Howartz1996,Davis2010}.  

Recent work shows that cohorts' importance transfers to online communities as well. Just as people's behavior varies according to their biological age, their experience in an online community may vary with their age in the community and their year of joining. In Wikipedia, we find substantial differences in the activities of cohorts of users who joined earlier versus those who joined later \cite{Welser2011}. Similarly, on review websites, users who join later tend to adopt different phrases than the older users who had joined earlier \cite{Danescu-niculescu-mizil2013}.

\subsection{What might cause these differences?}

These differences in activity between cohorts may be due to a number of reasons.  One plausible explanation is selection effects: people who are enthusiastic about a community or its goals are more likely to self-select as early members of a community, while others may be more likely to join later \cite{Li2008}.  In this case, users who join earlier might be expected to be more active, committed users than those who join later. 

Another possible explanation is that community norms may change over time.  In many cases, it is a bottom-up process. Kooti et al. showed that social conventions can define the evolution of a community and the early adopters play a major role in designing these conventions, consciously or not \cite{Kooti2010}. Examples include adoption of `RT', a retweeting norm by Twitter users and the subsequent introduction of the Retweet button on Twitter \cite{Kooti2010}; change in language use between new and old users on review websites \cite{Danescu-niculescu-mizil2013}; and assumptions of clear roles and responsibilities on Wikipedia \cite{Kittur2007a}. In other cases, it may be directed by the community managers. For instance, the makers of Digg unilaterally changed the nature of the community by introducing a new version of the website, leading to a sudden change in norms and behavior in the community \cite{Ingram2014,Lardinois2014}. 

The growth of a community may also affect people's behavior. Successful communities often grow very rapidly, which can be both good and bad for users' experience. On one hand, growth would imply availability of a larger chunk of content to choose from. On the other, it might be harder to connect to others and get responses in a bigger community. A community may also need to adopt new rules and policies to manage growth and newcomers, as in the evolution of Wikipedia \cite{Choi2010,Bryant2005}. In those cases, the experience of later cohorts of users may be vastly different from the initial ones who joined before formal rules were in place. 

Finally, patterns of use may change because the overall population of Internet users is still changing.  As more and different people come online, their influx may lead to changes in activity patterns and communities (as with the yearly entry of college freshmen, and eventually all of AOL, gaining access to Usenet).  The gradual penetration of technology also has age-related effects:  people who did not grow up in a technological environment differ in their social media and search usage compared to younger generations\cite{Correa2010,Beldona2005}. 

\subsection{Is Reddit getting ``worse'' over time?}
All of the above reasons suggest that users from different cohorts are likely to be different, which has also been demonstrated in online and offline communities \cite{Ryder1965,Danescu-niculescu-mizil2013,Prensky2001,Correa2010}.  Further, they suggest a general hypothesis that communities ``get worse'' over time because newer users are likely to be less committed and knowledgeable about the community. 

To address this hypothesis, we analyze both aggregate and cohort-based measures of user quality that are often raised about online communities: how active are users \cite{Scellato2011,Hughes2009,Java2007,Levy1984}, how much do they contribute \cite{Scellato2011,Gruhl2004,Guo2009}, and what kinds of work do they engage in \cite{Welser2011,Choi2010,Panciera2009}?  

We do this in the context of Reddit, a community that has been studied by many researchers \cite{Gilbert2013,Stoddard2015,Bergstrom2011,Tan2015}. We begin with a brief overview of both Reddit and the dataset that we use in this paper, focusing on aspects that directly impact our analyses\footnote{There is more to say about Reddit itself (see \cite{AboutReddit}).}.

