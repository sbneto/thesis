\chapter{Conclusions and Final Remarks}

\section{Conclusion and Future Work escience15}

This paper presented a novel method of capturing some of a user's non-explicit reactions to followees' content in Twitter by using text similarity scores between a user's tweets and those of their followees.  The analysis indicates that the method does generate higher scores on average for system tagged Replies and Retweets than Non-Tagged tweets, suggesting that it captures real signal about responses.  Using a conservative cutoff for predicting whether a non-tagged tweet is a response suggests that at least \highNonTaggedTweetCountPct{}\% of actual responses are not tagged by the system.  These responses are distributed across almost a quarter of the users in the dataset, with a quarter of those having more missed reaction messages than explicit system tagged ones. These are not just naive, low-activity users who do not understand Twitter and might be ignored in analysis; a number of these users are quite active, with dozens or hundreds of tweets in a 14-day window.  

Although the method has provided useful insights into the prevalence of non-explicit replies in Twitter, it is a coarse model.  It tends to under-evaluate Replies; is more sensitive to Retweet size than desirable; likely misses a number of non-explicit responses that have lower scores but are nonetheless real responses to the feed; and doesn't address responses to content outside the feed such as views by hashtag or username.  Ongoing work aims at addressing these limitations by improving the quality of the scoring function.  One natural way of improving the scoring function is to incorporate other relevant social features highlighted by past work (Table~\ref{tab:characteristics}).  We expect that better models of language, network characteristics, and attention that build on these features would give better estimates of how people react to content produced by their followees.

Another possible unfolding research topic is how to use these reaction scores to understand the reaction patterns and estimate the individual reaction level for each user.  This is important for effective models of diffusion at all levels, from understanding when adding an individual to a follower network might be most valuable, to estimating the overall reach of an individual's network, to modeling diffusion of information in the large.  Missing \highNonTaggedTweetCountPct{}\% of responses and \usersAboveLinePct{}\% users is a substantial amount of error to bear for such models, making the identification of non-explicit responses an important problem to pursue.


\section{Discussion and Future Work www16}

In this section we discuss some of the processes that might explain our observations, and how they connect to other literature.  We're not arguing here that we know the answers; instead, we see these as interesting avenues for future work.  

\subsection{Why are newer ``active'' users less so?}

We have seen that users from later cohorts have a lower posting average than in earlier cohorts. 
One plausible explanation is that users self-select: users that find Reddit early in its life are also more likely than average to be those who will be attracted to it. Previous work has shown that online book reviews have a self-selection bias, where people who are more likely to like (or promote) the book review it earlier, leading to a positive early bias in an item's life \cite{Li2008}.  In Reddit's case, this would mean that the mixture of users joining in the early stage of the community would be disproportionately likely to be the most active ones and the latter ones are more likely to be less active; several of our results support this explanation.

Another plausible hypothesis for later cohorts having a higher number of less active users could be that, over time, Reddit has accumulated an increasing number of valuable-but-small/niche communities.  The increased diversity might support a wider set of users in getting value, explaining the increased survival percentage.  The niche/smaller nature of newer communities might provide fewer opportunities to both submit and comment, explaining the lower average activity for surviving users. 

A third hypothesis is that Reddit overall is becoming more about consumption and voting on content rather than producing it.  Older users with contribution norms continue to contribute; newer users tend to provide audiences and feedback.  High-resolution voting data could be a real boon in understanding if this is true.

\subsection{Why are comments getting shorter?}

We also observed that overall, comment lengths are getting shorter over time.  
One hypothesis is that users' behavior is being shaped by an ``initial value problem''---that as users join the network, they tend to produce content according to the norms of what they see \cite{Kooti2010, Danescu-niculescu-mizil2013}. 
Figure~\ref{fig:comment_length}a presents some support for this hypothesis: the initial month of each cohort year, which consists of data only from users who joined in that month, is quite close to the overall line from the prior month.  

Another hypothesis advanced by community members\cite{RedditHypo1} is that Reddit's karma system favors shorter comments.  That is, people can get more upvotes for a given amount of effort by writing more, shorter comments.  This could be directly measured even with the available data, and might be the start of a very interesting line of future work around modeling strategic posting and attention distribution behavior in Reddit. 

\subsection{Why do comments per submission increase?}

We also saw that comments per submission increase over time for surviving users, especially for users who join earlier.

One process hypothesis is that this is because early in Reddit's life, there simply weren't as many submissions to comment on, meaning that people who wanted to be active contributors more or less had to submit in order to do so. 
As the community grew, more content became available to comment on; those comments in turn provide additional opportunities for commenting.  In this reading, the value and ease of commenting has increased over time, making it a more common behavior. 

This question of ease and value might be more general, and tie to our observations about self-selection and karma accumulation.  Most users in social networks are known to be lurkers: seeking information and observing, rather than contributing content \cite{Rafaeli2004, Nonnecke2000}. Consumption in Reddit is valuable and easy, and some contributions are easier than others: reading is easier than voting; voting is easier than commenting; commenting is easier than submitting.  Only users for whom finding and submitting comments is relatively easy or relatively valuable are likely to be frequent submitters or ``power users'' \cite{Panciera2009, Kittur2007}. We suspect such users are more likely to be ones who found Reddit earlier, when it was relatively small, and stuck with it.

\subsection{Limitations and Future Work}

In this paper we focused our attention on visible behavior attributable to specific users, which in this dataset meant submissions and comments.  As with many analyses that focus on visible behavior, this means we miss important phenomena.  In particular, we discount lurkers despite their known importance as audience members \cite{Nonnecke2003} and potential future contributors \cite{Ridings2006}.  Many lurkers likely vote, and thus lurking may be even more important in a context like Reddit where votes affect content visibility and provide explicit markers of attention and reputation.  

However, the dataset does not have information on individual voters or timestamps, just the aggregate number of votes a post had received at the time of the crawl, making it impossible to use them as activity measures for specific users.  The existing voting data might be much more useful, however, in addressing questions that involve predicting a given user's future behavior based on how other users respond to a user's early contributions \cite{Joyce2006,Sarkar2012}.

Focusing on visible activity can lead to blind spots in other places, as well.  In particular, our emphasis on active users led us to ignore questions of survival, leaving, and rejoining.  This was a reasonable view of the community based on the questions we were asking, but our results should all be interpreted in the context of ``given the set of active users at any given time''.  Applying these results to questions that require considering all users would be a mistake.  

We did, implicitly, consider survival in the analyses that broke cohort down by survival time; more generally, we see careful thinking about what it means to ``survive'' in a community as an interesting problem in its own right.  Many analyses assume that a gap of some time period implies that a user has left, or that users ``die'' on their last visible day of activity.  However, long gaps are common in real behavior.  People temporarily quit social media all the time \cite{Baumer2013}, and in Wikipedia, the practice of leaving temporarily is so common it has a name: ``wikibreak''.    Rather than an annoying right censorship statistical problem, this question of what it means when contributors to a community start and stop might pose a much more central issue, as a community's survival might not depend only in its ability to attract and retain users, but also in the ability to ``resurrect'' old users and leverage ``bursty'' ones.

Further, One of our assumptions was that one account is associated with one user. This might not be the case, as more than one user can share the same account \cite{Lampinen2014} or one user can have multiple accounts \cite{Bergstrom2011}.  Multiple accounts can have many functions, including making points someone doesn't want connected with their main identity, trolling or harming other users or the community, or simulating users who agree with a main identity (``sock puppets'').  While we think this is not the main driver of our results, this should be checked in future work---and sockpuppet detection and account deanonymization is an interesting question in its own right.

Finally, focusing on visible activity can also lead to blind spots around deleted content or communities.  At least in Reddit, activity from users is marked with a username of ``[deleted]'', which we discovered after realizing that one author had millions of comments(!), and that allowed us to consciously choose to exclude that data.  However, in some contexts, such as Wikipedia articles that are deleted, that activity is invisible as edit behavior on those articles does not show up in many data dumps.  Such invisible activity might be important in understanding either individual users or the community. 

\section{Conclusions}

This work highlights the importance of taking time into consideration when analyzing users' evolution in social networks. We do so by cohorting the users based on their creation year. Although simple, this approach provides a number of insights that would be missed by straightforward aggregate analysis methods.  We also analyze the evolution of users and communities from a shifted time referential: considering the time of an action in relation to the user creation date. This also reveals unexpected phenomena that we would otherwise not notice.

While analyzing how the amount of posting changes over time (\textbf{RQ1}), we found that user posting activity for surviving Reddit users is actually significantly higher than a naive average would suggest, that older users who survive are considerably more active than younger survivors, and that these newer users are unlikely to catch up (\textbf{RQ1a}).  Controlling for survival provided evidence for hypothesis (\textbf{H2}), that users have a stable level of posting activity over time (with slightly decreasing patterns).  Further, the percentage of surviving but low-activity users is increasing in the younger cohorts 

When looking at changes in comment length over time \textbf{RQ2} as a proxy for users' effort, we found that while the overall average in Reddit seems to decrease, users actually write longer comments as they survive, no matter when they join.  However, later cohorts of users that joined the network are writing smaller comments; their greater number leads to an instance of Simpson's paradox, where the overall average decreases while the series for each individual cohort increases. 

Finally, we analyze whether users change their commenting versus submission behavior over time (\textbf{RQ3}). 
We found that users with a higher initial comment to submission ratio survive longer on average, and that this ratio increases for surviving users, particularly for earlier cohorts.  This isn't because activity rises overall, as posting activity remains stable; instead, it suggests that longer-term users substitute commenting for submissions. 

An important remark of this paper is how different demographics of users joining and leaving a network play a significant role in shaping the average user behavior. Failing to account for these might limit our interpretation of the data (\textbf{H1}, \textbf{H3} or \textbf{H4}) and lead to wrong conclusions.

Both our and work and its limitations suggest fruitful directions for better understanding of users' evolution in both Reddit and online communities in general, directions we hope inspire other work in this area.  
